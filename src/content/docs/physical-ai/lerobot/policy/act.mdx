---
title: 'ACT (Action Chunking with Transformers)'
description: '정밀한 로봇 조작을 위한 Transformer 기반 모방 학습 알고리즘'
---

import Callout from '../../../../../components/Callout.astro';
import Tabs from '../../../../../components/Tabs.astro';

# ACT (Action Chunking with Transformers)

ACT는 복잡한 로봇 조작 작업을 위한 혁신적인 모방 학습 알고리즘입니다. 단 10분의 인간 시연만으로 80-90%의 성공률을 달성할 수 있습니다.

<Callout type="tip" title="ACT의 특징">
  - **Action Chunking**: 단일 액션이 아닌 액션 시퀀스 예측
  - **Temporal Ensembling**: 부드러운 동작을 위한 시간적 앙상블
  - **빠른 학습**: RTX 3090에서 5시간 내 학습 완료
  - **SO-ARM101 성공 사례 다수**: 저가의 하드웨어에서도 간단한 작업이 완수된 사례가 많음
</Callout>

<Callout type="info" title="필자 의견">
  **ACT 모델을 사용해본 개인적인 경험을 공유합니다:**
  
  - Pre-Trained 모델이 아니라 바닥부터 학습해서 보통 사용합니다.
  - 아주 작고 효율적이라서 간단한 Task를 학습하고 구동할 수 있습니다.
  - 꽤 잘 되는데... **Overfit이 심합니다**. 조명이나 물체 등 환경이 변하면 안 되는 경우가 많습니다.
  - 그래도 처음 시작하기엔 아주 좋은 모델입니다! 👍
</Callout>

## 개요

ACT는 Stanford에서 개발한 알고리즘으로, 다음과 같은 핵심 혁신을 통해 정밀한 로봇 조작을 가능하게 합니다:

## 핵심 개념

### Action Chunking
전통적인 방법이 한 번에 하나의 액션만 예측하는 것과 달리, ACT는 미래의 k개 액션을 한 번에 예측합니다.

### Temporal Ensembling
부드러운 로봇 동작을 위해 겹치는 액션 청크들을 가중 평균합니다.

<Callout type="info" title="작동 원리">
  시간 t에서 여러 정책 쿼리의 예측을 결합:
  - 시간 (t-2)에서 예측한 액션
  - 시간 (t-1)에서 예측한 액션  
  - 현재 시간 t에서 예측한 액션
  
  이들을 exponential weighting으로 평균하여 최종 액션 결정
</Callout>

## 사용 방법


### 1. 데이터셋 준비

```bash
# 로봇 시연 데이터 수집
python -m lerobot.record \
    --robot.type=so101 \
    --dataset.repo_id=${HF_USER}/act_dataset \
    --dataset.num_episodes=50 \
    --dataset.single_task="Pick and place object"
```

<Callout type="tip" title="데이터 수집 팁">
  - 최소 50개 에피소드 (10분 분량, 에피소드 길이마다 다를 수 있음)
  - 다양한 시작 위치에서 시연
  - 일관된 속도로 부드럽게 동작
</Callout>

### 2. 학습

<Tabs tabs={['기본 학습', '고급 설정']}>
  <div class="tab-panel">
    ```bash
    # ACT 모델 학습
    python -m lerobot.scripts.train \
        --dataset.repo_id=${HF_USER}/act_dataset \
        --policy.type=act \
        --output_dir=outputs/act_policy \
        --training.num_epochs=100 \
        --training.batch_size=64
    ```
  </div>
  <div class="tab-panel">
    ```bash
    # 고급 하이퍼파라미터 설정
    python -m lerobot.scripts.train \
        --dataset.repo_id=${HF_USER}/act_dataset \
        --policy.type=act \
        --policy.chunk_size=100 \
        --policy.n_encoder_layers=4 \
        --policy.n_decoder_layers=7 \
        --policy.n_heads=8 \
        --policy.hidden_dim=512 \
        --policy.dim_feedforward=3200 \
        --policy.kl_weight=10.0 \
        --training.learning_rate=1e-4 \
        --training.weight_decay=1e-4 \
        --wandb.enable=true
    ```
  </div>
</Tabs>

### 3. 추론 및 실행

```bash
# 학습된 정책으로 로봇 제어
python -m lerobot.scripts.eval \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyUSB0 \
    --policy.path=outputs/act_policy/checkpoint_best.pt \
    --policy.chunk_size=100 \
    --dataset.num_episodes=20
```


## SmolVLA와의 비교

| 특징 | ACT | SmolVLA |
|-----|-----|---------|
| 자연어 명령 | ❌ 미지원 | ✅ 지원 |
| 파라미터 수 | ~80M | 450M |
| 학습 속도 | 빠름 | 느림 |
| 정밀도 | 매우 높음 | 높음 |
| 작업 특화성 | 단일 작업 | 다중 작업 |

## 실제 성능

### 검증된 작업들 (ALOHA 기준...)
- **배터리 삽입**: 90% 성공률
- **벨크로 부착**: 85% 성공률
- **물체 집어 담기**: 95% 성공률
- **정밀 조립**: 80% 성공률

<Callout type="success" title="ACT 활용 시나리오">
  - **정밀 조작**: 밀리미터 단위 정확도가 필요한 작업
  - **빠른 학습**: 제한된 데이터로 높은 성능 달성
  - **실시간 제어**: 100Hz 제어 루프 지원
</Callout>

## 추가 리소스

- [ACT 원본 논문](https://arxiv.org/abs/2304.13469)
- [Stanford ALOHA 프로젝트](https://tonyzhaozh.github.io/aloha/)
- [구현 세부사항](https://github.com/tonyzhaozh/act)
- [LeRobot ACT 예제](https://github.com/huggingface/notebooks/blob/main/lerobot/training-act.ipynb)

---

*ACT는 Stanford의 Tony Z. Zhao 등이 개발했으며, LeRobot에서 최적화된 구현을 제공합니다.*