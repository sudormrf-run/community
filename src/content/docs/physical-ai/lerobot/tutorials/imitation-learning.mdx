---
title: 'SO-ARM101 Pick & Place 튜토리얼'
description: 'SO-ARM101과 ACT로 물체 집어 담기 작업 학습하기'
---

import Callout from '../../../../../components/Callout.astro';

# SO-ARM101 Pick & Place 튜토리얼

이 튜토리얼에서는 SO-ARM101 로봇과 ACT(Action Chunking with Transformers) 모델을 사용하여 물체를 집어서 바구니에 담는 작업을 학습시키는 전체 과정을 다룹니다.

<Callout type="info" title="필요 사항">
  - **하드웨어**: SO-ARM101 (리더+팔로워)
  - **카메라**: USB 웹캠 1대
  - **작업 물체**: 작은 블록 또는 장난감
  - **목표 바구니**: 투명한 플라스틱 통
</Callout>

## 작업 목표

로봇이 테이블 위의 물체를 집어서 바구니에 담는 작업을 자율적으로 수행하도록 학습시킵니다.

## 1. 환경 설정

### 작업 공간 준비

<Callout type="tip" title="설정 팁">
  - **카메라 위치**: 작업 공간 전체가 보이도록 45도 각도로 설치
  - **바구니 선택**: 투명한 플라스틱 통 사용 (물체 확인 용이)
  - **조명 설정**: 그림자가 적게 생기도록 균일한 조명
  - **작업 공간**: 로봇 팔 기준 반경 30cm 이내
</Callout>

### SO-ARM101 연결 및 테스트
```bash
# 1. 디바이스 확인
python -m lerobot.scripts.find_devices

# 2. 리더-팔로워 연결 테스트
python -m lerobot.teleoperate \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyUSB0 \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyUSB1
```

## 2. 데이터 수집

### 작업 시연 녹화
```bash
# Pick & Place 데이터셋 생성
export TASK_NAME="pick_and_place_basket"
export HF_USER="your_username"

python -m lerobot.record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyUSB0 \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyUSB1 \
    --robot.cameras="webcam" \
    --dataset.repo_id=${HF_USER}/${TASK_NAME} \
    --dataset.single_task="Pick object and place in basket" \
    --dataset.num_episodes=100 \
    --warmup_time_s=3 \
    --episode_time_s=15 \
    --reset_time_s=5
```

### 데이터 수집 프로토콜

<Callout type="warning" title="중요한 시연 규칙">
  1. **시작 위치**: 로봇 팔은 항상 홈 포지션에서 시작
  2. **물체 위치**: 5개의 다른 위치에서 각 20회씩 시연
  3. **속도**: 일정한 속도로 부드럽게 움직이기
  4. **그립**: 물체를 확실하게 잡았는지 확인 후 이동
</Callout>

### 위치별 데이터 수집
```bash
# 5개 위치에서 각각 20 에피소드씩
for i in {1..5}; do
    echo "=== Position $i: 20 episodes ==="
    echo "물체를 Position $i에 놓고 Enter를 누르세요..."
    read
    
    python -m lerobot.record \
        --dataset.repo_id=${HF_USER}/${TASK_NAME} \
        --dataset.num_episodes=20 \
        --dataset.tags="position_$i" \
        --resume
done
```

## 3. 데이터 검증

```bash
# 수집한 데이터 시각화
python -m lerobot.serve_dataset \
    --dataset.repo_id=${HF_USER}/${TASK_NAME} \
    --port=8080

# 브라우저에서 http://localhost:8080 접속
```

## 4. ACT 모델 학습

### 학습 설정
```bash
# ACT 모델 학습 시작
python -m lerobot.scripts.train \
    --dataset.repo_id=${HF_USER}/${TASK_NAME} \
    --policy.type=act \
    --output_dir=outputs/act_${TASK_NAME} \
    --policy.device=cuda \
    --training.num_epochs=500 \
    --training.batch_size=32 \
    --training.learning_rate=1e-4 \
    --wandb.enable=true \
    --wandb.project="so101_pick_place"
```

### 학습 모니터링
```python
# 학습 중 W&B에서 실시간으로 확인할 수 있는 메트릭:
# - loss/total: 전체 손실
# - loss/action: 액션 예측 손실
# - validation/success_rate: 검증 성공률
```

## 5. 모델 평가 및 실행

### 실시간 평가
```bash
# 학습된 모델로 실제 작업 수행
python -m lerobot.scripts.eval \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyUSB0 \
    --robot.cameras="webcam" \
    --policy.path=outputs/act_${TASK_NAME}/checkpoint_best.pt \
    --dataset.num_episodes=20 \
    --dataset.repo_id=${HF_USER}/${TASK_NAME}_eval
```

### 성공률 측정
```bash
# 20회 테스트 후 성공률 자동 계산
# 성공 기준: 물체가 바구니 안에 들어감
```

## 6. 문제 해결 및 최적화

### 일반적인 문제와 해결책

<Callout type="warning" title="낮은 성공률 (70% 미만)">
  **원인**: 데이터 부족 또는 일관성 부족
  
  **해결책**:
  - 실패한 위치에서 추가 20개 데이터 수집
  - 속도를 더 일정하게 유지
  - 그립 강도 조정
</Callout>

<Callout type="danger" title="물체를 놓치는 경우">
  **원인**: 그립 타이밍 문제
  
  **해결책**:
  ```bash
  # 그립 지속 시간 증가
  python -m lerobot.scripts.train \
      --policy.action_chunk_size=50 \
      --resume
  ```
</Callout>

## 결과 공유

```bash
# HuggingFace에 모델 업로드
huggingface-cli upload ${HF_USER}/act_so101_pick_place \
    outputs/act_${TASK_NAME}/checkpoint_best.pt

# 데모 비디오 생성
python -m lerobot.scripts.create_demo_video \
    --policy.path=outputs/act_${TASK_NAME}/checkpoint_best.pt \
    --output=demo_pick_place.mp4
```

## 기대 성능

| 지표 | 목표값 | 일반적 달성값 |
|-----|-------|------------|
| 성공률 | 90% 이상 | 85-95% |
| 평균 수행 시간 | 10초 이내 | 8-12초 |
| 필요 데이터 | 100 에피소드 | 80-120 |

<Callout type="success" title="축하합니다!">
  SO-ARM101으로 첫 번째 Pick & Place 작업을 성공적으로 학습시켰습니다!
  
  **다음 도전 과제**:
  - 다양한 물체 종류로 확장
  - 여러 개의 바구니 구분하기
  - 색상별 분류 작업
</Callout>

---

*이 튜토리얼의 전체 코드와 데이터셋은 [HuggingFace Hub](https://huggingface.co/lerobot)에서 확인할 수 있습니다.*